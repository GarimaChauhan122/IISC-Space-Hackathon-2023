{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjJ_hZteiSVS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import statistics as st\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Conv2D, Flatten, MaxPooling2D\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,jaccard_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As the 10m resolution training data is unavailable, so we have to mannually generated it. For this we are using the True color sentinel-2A image(tcl_image.tif) of the region given in the input dataset of the PS-20. We semi-automatically labelled the data into 6 classes represented by 6 different color code that we know using the Google Earth Engine and named the image as 'labelled_image'.\n",
        "The approach is straightforward, we will divide both the images simultaneously into 32x32 sub-images such that, the class assigned to 32x32 sub-image of the True color image, corresponds to the class of respective 32x32 sub-image of the labelled_image. As we know that each pixel of 32x32 sub-image of the labelled_image belong to a known set of color code, so we will take mode of the color codes and assign class corresponding to that color .\n",
        " We are saving the sub-images of the True color images in their respective folders.This methodology can be ectended to 18 classes. Different locations and seasons data need to be processed similarly for accumulate a better trainig dataset.**"
      ],
      "metadata": {
        "id": "nDlfySJQj-AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load your TCl_sentinel image and labeled image here\n",
        "tcl_image = cv2.imread('/content/drive/MyDrive/Aiwizards/sentinel_image_rgb2.tif')\n",
        "labeled_image = cv2.imread('/content/drive/MyDrive/Aiwizards/classified_image_rgb02.tif', cv2.IMREAD_UNCHANGED)  # Replace with your labeled image\n",
        "\n",
        "# Define class names\n",
        "class_names = ['Class0_BlackWaste', 'Class1_Water', 'Class2_Buildup', 'Class3_Barrenland', 'Class4_Cropland', 'Class5_Vegetation']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wuzomGii114",
        "outputId": "c34e935f-b266-4172-f873-f3b5ffd7a4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract subimages and save them to corresponding folders\n",
        "def extract_and_save_subimages(tcl_image, labeled_image,output_dir,output_dir_outlier, subimage_size=(32, 32, 3)):\n",
        "    # Create output directories if they don't exist\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(output_dir, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(output_dir_outlier, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "    # Get the height and width of the images\n",
        "    height, width, _ = tcl_image.shape\n",
        "\n",
        "    # Iterate through the images and extract subimages\n",
        "    for y in range(0, height - subimage_size[0] + 1, subimage_size[0]):\n",
        "        for x in range(0, width - subimage_size[1] + 1, subimage_size[1]):\n",
        "            subimage_tcl = tcl_image[y:y + subimage_size[0], x:x + subimage_size[1]]\n",
        "            subimage_label = labeled_image[y:y + subimage_size[0], x:x + subimage_size[1]]\n",
        "\n",
        "            # Determine the class based on the mode of pixel values in the labeled subimage\n",
        "            pixel_color = []\n",
        "            for i in range(subimage_size[0]):\n",
        "                for j in range(subimage_size[1]):\n",
        "                    if np.array_equal(subimage_label[i][j], [0, 0, 0]):\n",
        "                        pixel_color.append(0)\n",
        "                    elif np.array_equal(subimage_label[i][j], [255, 0, 0]):\n",
        "                        pixel_color.append(1)\n",
        "                    elif np.array_equal(subimage_label[i][j], [255, 255, 255]):\n",
        "                        pixel_color.append(2)\n",
        "                    elif np.array_equal(subimage_label[i][j], [0, 0, 255]):\n",
        "                        pixel_color.append(3)\n",
        "                    elif np.array_equal(subimage_label[i][j], [85, 255, 85]):\n",
        "                        pixel_color.append(4)\n",
        "                    elif np.array_equal(subimage_label[i][j], [0, 255, 0]):\n",
        "                        pixel_color.append(5)\n",
        "                    else:\n",
        "                        print(subimage_label[i][j])\n",
        "\n",
        "            if(st.mode(pixel_color)==0 and ((pixel_color.count(st.mode(pixel_color))*100)/1024)>30):\n",
        "                class_index = st.mode(pixel_color)\n",
        "                class_name = class_names[class_index]\n",
        "                output_path = os.path.join(output_dir, class_name, f\"subimage_{y}_{x}.tif\")\n",
        "                cv2.imwrite(output_path, subimage_tcl)\n",
        "            if(st.mode(pixel_color)!=0 and ((pixel_color.count(st.mode(pixel_color))*100)/1024)>50):\n",
        "                class_index = st.mode(pixel_color)\n",
        "                class_name = class_names[class_index]\n",
        "                output_path = os.path.join(output_dir, class_name, f\"subimage_{y}_{x}.tif\")\n",
        "                cv2.imwrite(output_path, subimage_tcl)\n",
        "            if (st.mode(pixel_color) == 0 and (((pixel_color.count(st.mode(pixel_color)) * 100) / 1024) <= 30 or ((pixel_color.count(st.mode(pixel_color)) * 100) / 1024) == 100)):\n",
        "                class_index = st.mode(pixel_color)\n",
        "                class_name = class_names[class_index]\n",
        "                output_path = os.path.join(output_dir_outlier, class_name, f\"subimage_{y}_{x}.tif\")\n",
        "                cv2.imwrite(output_path, subimage_tcl)\n",
        "            if (st.mode(pixel_color) != 0 and ((pixel_color.count(st.mode(pixel_color)) * 100) / 1024) <= 50):\n",
        "                class_index = st.mode(pixel_color)\n",
        "                class_name = class_names[class_index]\n",
        "                output_path = os.path.join(output_dir_outlier, class_name, f\"subimage_{y}_{x}.tif\")\n",
        "                cv2.imwrite(output_path, subimage_tcl)\n",
        "\n",
        "\n",
        "# Call the function to extract and save subimages\n",
        "output_dir=\"train_subimages32\" #path where the sub-images divided be stored\n",
        "output_dir_outlier=\"tain_subimage32_outlier\"\n",
        "extract_and_save_subimages(tcl_image, labeled_image,output_dir,output_dir_outlier)\n",
        "\n"
      ],
      "metadata": {
        "id": "XBTKAt-apsL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and train the CNN model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to create and train the CNN model\n",
        "def create_and_train_model(input_shape, num_classes, class_weights, train_dir, test_dir, epochs=65):\n",
        "    # Create the CNN model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', input_shape=input_shape, activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='valid'))\n",
        "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='valid'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(768, activation='relu'))\n",
        "    model.add(Dense(384, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    # Use the ImageDataGenerator for data augmentation and preprocessing\n",
        "    datagen =  tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255, validation_split=0.15)\n",
        "\n",
        "    # Split the data into training, validation, and testing sets\n",
        "    train_generator = datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=input_shape[:2],\n",
        "        batch_size=1000,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        subset='training',\n",
        "        seed=40\n",
        "    )\n",
        "    validation_generator = datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=input_shape[:2],\n",
        "        batch_size=1000,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False,\n",
        "        subset='validation',\n",
        "        seed=40\n",
        "    )\n",
        "\n",
        "    # Train the model with validation data\n",
        "    history = model.fit(train_generator, epochs=epochs, class_weight=class_weights, validation_data=validation_generator)\n",
        "\n",
        "    # Save the model weights to a file\n",
        "    model.save_weights('/content/drive/MyDrive/Aiwizards/Model_weightsANDtaining_plots/model_weights04_final.h5')\n",
        "\n",
        "    # Alternatively, you can have a separate directory for testing\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=input_shape[:2],\n",
        "        batch_size=200,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False,\n",
        "        seed=40\n",
        "    )\n",
        "\n",
        "\n",
        "    test_results = model.evaluate(test_generator)\n",
        "    print(\"Test Loss:\", test_results[0])\n",
        "    print(\"Test Accuracy:\", test_results[1])\n",
        "\n",
        "    # Generate predictions for the testing set\n",
        "    y_true = test_generator.classes\n",
        "    y_pred_prob = model.predict(test_generator)\n",
        "    y_pred = tf.argmax(y_pred_prob, axis=1).numpy()\n",
        "\n",
        "\n",
        "    # Calculate and print additional metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
        "\n",
        "    # Calculate and print F1 Score, Precision, Recall, and IoU\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    iou = jaccard_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"IoU: {iou:.4f}\")\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot training and validation accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plots to a file\n",
        "    plt.savefig('/content/drive/MyDrive/Aiwizards/Model_weightsANDtaining_plots/training_plots04_final.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "# Path to the directory containing the training images\n",
        "train_dir = \"/content/drive/MyDrive/Aiwizards/train_subimages32.zip\"\n",
        "test_dir=\"/content/drive/MyDrive/Aiwizards/test_subimages32.zip\"\n",
        "# Number of classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Calculate class weights for imbalanced data\n",
        "class_counts = [len(os.listdir(os.path.join(train_dir, class_name))) for class_name in class_names]\n",
        "total_samples = sum(class_counts)\n",
        "class_weights = {i: total_samples / (num_classes * class_counts[i]) for i in range(num_classes)}\n",
        "print(class_weights)\n",
        "# Model input shape and subimage size\n",
        "input_shape = (32, 32, 3)\n",
        "subimage_size = (32, 32, 3)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_and_train_model(input_shape, num_classes, class_weights, train_dir,test_dir)\n"
      ],
      "metadata": {
        "id": "zLidfM4JwVEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing data has 6 folders representing each class testing data. The testing data have been generated in the same way as the training data."
      ],
      "metadata": {
        "id": "CUzVUqcc9TLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###USER END TESTING\n",
        "# Define class names\n",
        "class_names = ['Class0_BlackWaste', 'Class1_Water', 'Class2_Buildup', 'Class3_Barrenland', 'Class4_Cropland', 'Class5_Vegetation']\n",
        "num_classes = len(class_names)\n",
        "input_shape = (32, 32, 3)\n",
        "subimage_size = (32, 32, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', input_shape=input_shape, activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='valid'))\n",
        "model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(768, activation='relu'))\n",
        "model.add(Dense(384, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.load_weights('model_weights04_final.h5')\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Function to create an image with labeled subimages and evaluate on test data\n",
        "def create_labeled_image_and_evaluate(model, subimage_size, testing_map, test_dir):\n",
        "    ##When a large image of dimention like 1920X10280 given-\n",
        "\n",
        "    # Load the large image\n",
        "    large_image_path =testing_map  # Replace with the path to your large image\n",
        "    large_image = cv2.imread(large_image_path)\n",
        "    print(type(large_image))\n",
        "    labeled_image = np.zeros((large_image.shape[0], large_image.shape[1], 3), dtype=np.uint8)\n",
        "    large_image = cv2.resize(large_image, (large_image.shape[1] // subimage_size[1] * subimage_size[1],\n",
        "                                           large_image.shape[0] // subimage_size[0] * subimage_size[0]))\n",
        "\n",
        "    # Initialize the labeled image\n",
        "    labeled_image = np.zeros_like(large_image)\n",
        "\n",
        "    # Divide the large image into sub-images and make predictions\n",
        "    for y in range(0, large_image.shape[0], subimage_size[0]):\n",
        "        for x in range(0, large_image.shape[1], subimage_size[1]):\n",
        "            subimg = large_image[y:y + subimage_size[0], x:x + subimage_size[1]]\n",
        "            subimg = cv2.resize(subimg, (subimage_size[1], subimage_size[0]))\n",
        "\n",
        "            # Predict the class of the subimage\n",
        "            pred_class = model.predict(np.expand_dims(subimg, axis=0))\n",
        "            pred_class = np.argmax(pred_class)\n",
        "\n",
        "            # Assign RGB values based on the predicted class\n",
        "            rgb_value = class_rgb_values[pred_class]\n",
        "\n",
        "            # Fill the corresponding region in the labeled image\n",
        "            labeled_image[y:y + subimage_size[0], x:x + subimage_size[1]] = rgb_value\n",
        "\n",
        "    # Save the labeled image\n",
        "    cv2.imwrite('labelled.png', labeled_image)\n",
        "    '''\n",
        "\n",
        "    # Generate the Classified Map, if the input is in same fiormat like we save the sub-images while generating the trainig data\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(test_dir, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            img = cv2.imread(os.path.join(class_dir, filename))\n",
        "            img = cv2.resize(img, (subimage_size[1], subimage_size[0]))\n",
        "\n",
        "            # Extract coordinates from the filename\n",
        "            y, x = map(int, filename.split('_')[1:3])\n",
        "\n",
        "            # Predict the class of the subimage\n",
        "            pred_class = model.predict(np.expand_dims(img, axis=0))\n",
        "            pred_class = np.argmax(pred_class)\n",
        "\n",
        "            # Assign RGB values based on the predicted class\n",
        "            rgb_value = class_rgb_values[pred_class]\n",
        "\n",
        "            # Fill the corresponding region in the labeled image\n",
        "            labeled_image[y:y + subimage_size[0], x:x + subimage_size[1]] = rgb_value\n",
        "\n",
        "    # Save the labeled image to Google Drive\n",
        "    cv2.imwrite(testing_map, labeled_image)\n",
        "    '''\n",
        "\n",
        "    #Evaluation\n",
        "\n",
        "    # Use the trained model for predictions on the test dataset\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=subimage_size[:2],\n",
        "        batch_size=1000,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Predict the classes\n",
        "    predictions = model.predict(test_generator)\n",
        "\n",
        "    # Convert predictions to class labels\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Get the true labels from the test dataset\n",
        "    true_labels = test_generator.classes\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    # Confusion Matrix for IoU calculation\n",
        "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "    intersection = np.diag(conf_matrix)\n",
        "    union = np.sum(conf_matrix, axis=0) + np.sum(conf_matrix, axis=1) - np.diag(conf_matrix)\n",
        "    iou = np.mean(intersection / union)\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"IoU: {iou:.4f}\")\n",
        "\n",
        "\n",
        "# RGB values for each class\n",
        "class_rgb_values = {\n",
        "    0: [0, 0, 0],\n",
        "    1: [85, 255, 255],\n",
        "    2: [255, 255, 255],\n",
        "    3: [255, 0, 0],\n",
        "    4: [85, 255, 85],\n",
        "    5: [0, 255, 0]\n",
        "}\n",
        "\n",
        "# Create the labeled image using the trained model and evaluate on test data\n",
        "testing_map ='/content/drive/MyDrive/Aiwizards/sentinel_image_rgb2.tif'\n",
        "test_dir = \"/content/drive/MyDrive/Aiwizards/train_subimages32.zip\"\n",
        "create_labeled_image_and_evaluate(model, subimage_size, testing_map, test_dir)"
      ],
      "metadata": {
        "id": "RBeiZxpX10SN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}